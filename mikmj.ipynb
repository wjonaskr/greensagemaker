{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8b4b2d3b-d706-425a-8aa4-e3bd40d4e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, sagemaker, joblib, os, tarfile, subprocess, time\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "import json\n",
    "\n",
    "# SageMaker ì„¸ì…˜ ë° ì—­í•  ì„¤ì •\n",
    "sagemaker_session = sagemaker.Session()\n",
    "#model_data = \"s3://greenenergy-ai-app-d-an2-s3-gem/sagemaker-models/async-20250729100023/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e40201fd-29d9-478f-aba2-0656aa6fffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "377e4fc3-9671-4c1a-a104-5a54bf7ca8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "69f32346-fe0d-4165-a37c-d74a9524fc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id = sagemaker_session.account_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "086c5995-d5f6-4600-b0d5-616aa06fb835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role :arn:aws:iam::154126116352:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\n",
      "region :ap-northeast-2\n",
      "id :154126116352\n"
     ]
    }
   ],
   "source": [
    "print(\"role :\" + role)\n",
    "print(\"region :\" + region)\n",
    "print(\"id :\" + account_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c98f4795-204f-4be9-b660-f4f324828bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ - RÂ²: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ìƒì„±\n",
    "X, y = make_regression(n_samples=100, n_features=2, random_state=42)\n",
    "model = LinearRegression().fit(X, y)\n",
    "os.makedirs('model', exist_ok=True)\n",
    "joblib.dump(model, 'model/model.joblib')\n",
    "print(f\"âœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ - RÂ²: {model.score(X, y):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aae2b53d-e311-4be5-a26a-d84e5fbcf151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì»¨í…Œì´ë„ˆ íŒŒì¼ ìƒì„± ì™„ë£Œ (Async ìµœì í™”)\n"
     ]
    }
   ],
   "source": [
    "# ì»¨í…Œì´ë„ˆ íŒŒì¼ ìƒì„± (Asyncìš©)\n",
    "os.makedirs('container', exist_ok=True)\n",
    "\n",
    "# predictor.py (Async ì²˜ë¦¬ ìµœì í™”)\n",
    "predictor = '''import joblib, numpy as np, json, os\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "model = joblib.load('/opt/ml/model/model.joblib')\n",
    "\n",
    "@app.route('/ping')\n",
    "def ping():\n",
    "    return jsonify({'status': 'healthy'})\n",
    "\n",
    "@app.route('/invocations', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        # Content-Type í™•ì¸\n",
    "        content_type = request.content_type\n",
    "        \n",
    "        if content_type == 'application/json':\n",
    "            data = request.get_json()\n",
    "        else:\n",
    "            # í…ìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬ (CSV ë“±)\n",
    "            data_str = request.data.decode('utf-8')\n",
    "            data = json.loads(data_str)\n",
    "        \n",
    "        instances = data.get('instances', data)\n",
    "        \n",
    "        # ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°°ì¹˜ ì²˜ë¦¬\n",
    "        if isinstance(instances, list) and len(instances) > 1000:\n",
    "            print(f\"Processing large batch: {len(instances)} instances\")\n",
    "        \n",
    "        predictions = model.predict(np.array(instances))\n",
    "        \n",
    "        return jsonify({\n",
    "            'predictions': predictions.tolist(),\n",
    "            'batch_size': len(instances),\n",
    "            'model_type': 'LinearRegression'\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8080)\n",
    "'''\n",
    "\n",
    "# Dockerfile\n",
    "dockerfile = '''FROM python:3.8-slim\n",
    "RUN pip install flask scikit-learn joblib numpy\n",
    "COPY predictor.py /opt/program/predictor.py\n",
    "WORKDIR /opt/program\n",
    "EXPOSE 8080\n",
    "ENTRYPOINT [\"python\", \"predictor.py\"]\n",
    "'''\n",
    "\n",
    "with open('container/predictor.py', 'w') as f: f.write(predictor)\n",
    "with open('container/Dockerfile', 'w') as f: f.write(dockerfile)\n",
    "\n",
    "print(\"âœ… ì»¨í…Œì´ë„ˆ íŒŒì¼ ìƒì„± ì™„ë£Œ (Async ìµœì í™”)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c3fb028c-2ab4-40e7-9c4f-829adb535b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„¹ï¸  ECR ë¦¬í¬ì§€í† ë¦¬ ì´ë¯¸ ì¡´ì¬: ns-gem/sagemaker\n",
      "ğŸ“¦ ECR URI: 154126116352.dkr.ecr.ap-northeast-2.amazonaws.com/ns-gem/sagemaker\n"
     ]
    }
   ],
   "source": [
    "# ECR ì„¤ì •\n",
    "ecr = boto3.client('ecr')\n",
    "repo_name = 'ns-gem/sagemaker'\n",
    "try:\n",
    "    ecr.create_repository(repositoryName=repo_name)\n",
    "    print(f\"âœ… ECR ë¦¬í¬ì§€í† ë¦¬ ìƒì„±: {repo_name}\")\n",
    "except ecr.exceptions.RepositoryAlreadyExistsException:\n",
    "    print(f\"â„¹ï¸  ECR ë¦¬í¬ì§€í† ë¦¬ ì´ë¯¸ ì¡´ì¬: {repo_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"â„¹ï¸  ECR ì„¤ì •: {str(e)}\")\n",
    "\n",
    "repo_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{repo_name}\"\n",
    "print(f\"ğŸ“¦ ECR URI: {repo_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "de84a39c-4b59-4d33-9f9f-ab1022814415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¨ Docker ë¹Œë“œ & í‘¸ì‹œ ì‹œì‘...\n",
      "âœ… Docker ë¹Œë“œ & í‘¸ì‹œ ì™„ë£Œ\n",
      "  8d853c8add5d: Layer already exists\n",
      "  c3772b569c3a: Layer already exists\n",
      "  async: digest: sha256:086f2981fd0f2f850f1a73fbf448e950299cdfe9f859373b5004044b06d78edc size: 1785\n",
      "  âœ… ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# Docker ë¹Œë“œ & í‘¸ì‹œ\n",
    "build_script = f'''#!/bin/bash\n",
    "set -e\n",
    "echo \"ğŸ” ECR ë¡œê·¸ì¸...\"\n",
    "aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin {account_id}.dkr.ecr.{region}.amazonaws.com\n",
    "\n",
    "echo \"ğŸ”¨ Docker ë¹Œë“œ...\"\n",
    "cd container\n",
    "docker build --platform linux/amd64 -t ns-gem-async .\n",
    "\n",
    "echo \"ğŸ·ï¸  íƒœê·¸ ì„¤ì •...\"\n",
    "docker tag ns-gem-async:latest {repo_uri}:async\n",
    "\n",
    "echo \"ğŸ“¤ ECR í‘¸ì‹œ...\"\n",
    "docker push {repo_uri}:async\n",
    "\n",
    "echo \"âœ… ì™„ë£Œ!\"\n",
    "'''\n",
    "\n",
    "with open('build_async.sh', 'w') as f: f.write(build_script)\n",
    "os.chmod('build_async.sh', 0o755)\n",
    "\n",
    "print(\"ğŸ”¨ Docker ë¹Œë“œ & í‘¸ì‹œ ì‹œì‘...\")\n",
    "result = subprocess.run(['bash', 'build_async.sh'], capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"âœ… Docker ë¹Œë“œ & í‘¸ì‹œ ì™„ë£Œ\")\n",
    "    # ë§ˆì§€ë§‰ ëª‡ ì¤„ë§Œ ì¶œë ¥\n",
    "    output_lines = result.stdout.split('\\n')\n",
    "    for line in output_lines[-5:]:\n",
    "        if line.strip():\n",
    "            print(f\"  {line}\")\n",
    "else:\n",
    "    print(f\"âŒ ë¹Œë“œ ì‹¤íŒ¨\")\n",
    "    print(f\"STDOUT: {result.stdout}\")\n",
    "    print(f\"STDERR: {result.stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "92012cda-9b28-4c81-a42d-d892ae6a9d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ ëª¨ë¸ S3 ì—…ë¡œë“œ ì¤‘...\n",
      "âœ… ëª¨ë¸ ì—…ë¡œë“œ ì™„ë£Œ: s3://greenenergy-ai-app-d-an2-s3-gem/sagemaker-models/async-20250903074245-test/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ S3 ì—…ë¡œë“œ\n",
    "print(\"ğŸ“¦ ëª¨ë¸ S3 ì—…ë¡œë“œ ì¤‘...\")\n",
    "bucket_name = 'greenenergy-ai-app-d-an2-s3-gem'\n",
    "with tarfile.open('model.tar.gz', 'w:gz') as tar:\n",
    "    tar.add('model/model.joblib', arcname='model.joblib')\n",
    "\n",
    "# ì§€ì •ëœ S3 ë²„í‚· ì‚¬ìš©\n",
    "s3 = boto3.client('s3')\n",
    "timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "s3_key = f'sagemaker-models/async-{timestamp}-test/model.tar.gz'\n",
    "\n",
    "s3.upload_file('model.tar.gz', bucket_name, s3_key)\n",
    "model_uri = f's3://{bucket_name}/{s3_key}'\n",
    "\n",
    "print(f\"âœ… ëª¨ë¸ ì—…ë¡œë“œ ì™„ë£Œ: {model_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2f00a441-deb7-44ee-bc14-4ae8d514d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ìƒì„±\n",
    "model_data=model_uri\n",
    "model = Model(\n",
    "    image_uri=f'{repo_uri}:async',\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e5041890-1aa4-4ad1-871c-faf73ce45c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async Inference ì„¤ì • (SNS ì•Œë¦¼ í¬í•¨)\n",
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "\n",
    "# SNS í† í”½ ARN\n",
    "sns_topic_arn = \"arn:aws:sns:ap-northeast-2:154126116352:sagemaker-async-notifications\"\n",
    "\n",
    "async_config = AsyncInferenceConfig(\n",
    "    output_path=\"s3://greenenergy-ai-app-d-an2-s3-gem/async-inference/output/\",\n",
    "    max_concurrent_invocations_per_instance=4,\n",
    "    failure_path=\"s3://greenenergy-ai-app-d-an2-s3-gem/async-inference/error/\",\n",
    "    notification_config={\n",
    "        \"SuccessTopic\": sns_topic_arn,\n",
    "        \"ErrorTopic\": sns_topic_arn\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"âœ… Async Inference Config with SNS notifications created\")\n",
    "print(f\"SNS Topic: {sns_topic_arn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "470a1f80-ebaa-4cb2-a407-c088e4fc2b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "# Async Endpoint ë°°í¬\n",
    "try:\n",
    "    predictor = model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        async_inference_config=async_config,\n",
    "        endpoint_name=\"test-async-endpoint3\"  # ì„ íƒì‚¬í•­\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë°°í¬ ì¤‘ ì˜¤ë¥˜: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "039d3fa8-bbbc-49b9-928d-468bce6d39c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_s3_uri = \"s3://greenenergy-ai-app-d-an2-s3-gem/async-inference-input/test-20250729100023.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "912b40e2-c51c-4c01-a3fa-afadeb4b33d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ê¸°ì¡´ ë°ì´í„°ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹œì‘\n",
      "ì…ë ¥ ë°ì´í„°: s3://greenenergy-ai-app-d-an2-s3-gem/async-inference-input/test-20250729100023.json\n",
      "{'ResponseMetadata': {'RequestId': 'bfa32a4f-04cb-4677-aa97-89520f6cafc5', 'HTTPStatusCode': 202, 'HTTPHeaders': {'x-amzn-requestid': 'bfa32a4f-04cb-4677-aa97-89520f6cafc5', 'x-amzn-sagemaker-outputlocation': 's3://greenenergy-ai-app-d-an2-s3-gem/async-inference/output/49779a19-b2b9-4c5e-8a48-1c38ba631ec2.out', 'x-amzn-sagemaker-failurelocation': 's3://greenenergy-ai-app-d-an2-s3-gem/async-inference/error/49779a19-b2b9-4c5e-8a48-1c38ba631ec2-error.out', 'date': 'Wed, 03 Sep 2025 07:47:26 GMT', 'content-type': 'application/json', 'content-length': '54', 'connection': 'keep-alive'}, 'RetryAttempts': 0}, 'OutputLocation': 's3://greenenergy-ai-app-d-an2-s3-gem/async-inference/output/49779a19-b2b9-4c5e-8a48-1c38ba631ec2.out', 'FailureLocation': 's3://greenenergy-ai-app-d-an2-s3-gem/async-inference/error/49779a19-b2b9-4c5e-8a48-1c38ba631ec2-error.out', 'InferenceId': '285c9f19-ac87-4108-91ab-34298e0e6305'}\n",
      "ì¶œë ¥ ìœ„ì¹˜: s3://greenenergy-ai-app-d-an2-s3-gem/async-inference/output/49779a19-b2b9-4c5e-8a48-1c38ba631ec2.out\n",
      "greenenergy-ai-app-d-an2-s3-gem\n",
      "async-inference/output/49779a19-b2b9-4c5e-8a48-1c38ba631ec2.out\n",
      "greenenergy-ai-app-d-an2-s3-gem\n",
      "async-inference/output/49779a19-b2b9-4c5e-8a48-1c38ba631ec2.out\n",
      "{'ResponseMetadata': {'RequestId': 'A4BAP9WDNDKAKSHY', 'HostId': 'jjrF/r/kdrzEW5OrPd6bzuMuPvluhEV2X/aR0cmwMKGJ0QSjNN3yf6cQdw/qNhb197sHbBGpXsY=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': 'jjrF/r/kdrzEW5OrPd6bzuMuPvluhEV2X/aR0cmwMKGJ0QSjNN3yf6cQdw/qNhb197sHbBGpXsY=', 'x-amz-request-id': 'A4BAP9WDNDKAKSHY', 'date': 'Wed, 03 Sep 2025 07:47:28 GMT', 'last-modified': 'Wed, 03 Sep 2025 07:47:28 GMT', 'etag': '\"1b331023795dea304e6b9069eb758951\"', 'x-amz-checksum-crc64nvme': 'qn0Jf7MXEPI=', 'x-amz-checksum-type': 'FULL_OBJECT', 'x-amz-server-side-encryption': 'aws:kms', 'x-amz-server-side-encryption-aws-kms-key-id': 'arn:aws:kms:ap-northeast-2:ACCOUNT_ID:key/KMS_KEY_ID', 'x-amz-server-side-encryption-bucket-key-enabled': 'true', 'accept-ranges': 'bytes', 'content-type': 'application/json', 'content-length': '158', 'server': 'AmazonS3'}, 'RetryAttempts': 0}, 'AcceptRanges': 'bytes', 'LastModified': datetime.datetime(2025, 9, 3, 7, 47, 28, tzinfo=tzutc()), 'ContentLength': 158, 'ETag': '\"1b331023795dea304e6b9069eb758951\"', 'ChecksumCRC64NVME': 'qn0Jf7MXEPI=', 'ChecksumType': 'FULL_OBJECT', 'ContentType': 'application/json', 'ServerSideEncryption': 'aws:kms', 'Metadata': {}, 'SSEKMSKeyId': 'arn:aws:kms:ap-northeast-2:ACCOUNT_ID:key/KMS_KEY_ID', 'BucketKeyEnabled': True, 'Body': <botocore.response.StreamingBody object at 0x7f33152d4310>}\n",
      "{'batch_size': 5, 'model_type': 'LinearRegression', 'predictions': [235.89103074363646, 189.13505980296617, 67.24663906673294, 278.6047574023252, 146.57656140507495]}\n",
      "âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ (1.09ì´ˆ)\n",
      "ì˜ˆì¸¡ ê²°ê³¼ ìˆ˜: 5\n",
      "ë°°ì¹˜ í¬ê¸°: 5\n",
      "ì²« ë²ˆì§¸ ì˜ˆì¸¡ê°’: [235.89103074363646, 189.13505980296617, 67.24663906673294]\n"
     ]
    }
   ],
   "source": [
    "def quick_test_existing_data():\n",
    "    endpoint_name = \"test-async-endpoint3\"\n",
    "    input_data = input_s3_uri\n",
    "    \n",
    "    print(\"ğŸš€ ê¸°ì¡´ ë°ì´í„°ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "    print(f\"ì…ë ¥ ë°ì´í„°: {input_data}\")\n",
    "    \n",
    "    runtime = boto3.client('sagemaker-runtime')\n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        # Async ì¶”ë¡  ìš”ì²­\n",
    "        response = runtime.invoke_endpoint_async(\n",
    "            EndpointName=endpoint_name,\n",
    "            InputLocation=input_data,\n",
    "            ContentType='application/json'\n",
    "        )\n",
    "        \n",
    "        output_location = response['OutputLocation']\n",
    "        print(response)\n",
    "        print(f\"ì¶œë ¥ ìœ„ì¹˜: {output_location}\")\n",
    "        \n",
    "        # ê²°ê³¼ ëŒ€ê¸°\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i in range(300):  # 5ë¶„ ëŒ€ê¸°\n",
    "            try:\n",
    "                bucket = output_location.split('/')[2]\n",
    "                print(bucket)\n",
    "                key = '/'.join(output_location.split('/')[3:])\n",
    "                print(key)\n",
    "                \n",
    "                result_obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "                print(result_obj)\n",
    "                result_data = json.loads(result_obj['Body'].read())\n",
    "                print(result_data)\n",
    "                \n",
    "                elapsed_time = time.time() - start_time\n",
    "                print(f\"âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ ({elapsed_time:.2f}ì´ˆ)\")\n",
    "                print(f\"ì˜ˆì¸¡ ê²°ê³¼ ìˆ˜: {len(result_data.get('predictions', []))}\")\n",
    "                print(f\"ë°°ì¹˜ í¬ê¸°: {result_data.get('batch_size', 'N/A')}\")\n",
    "                print(f\"ì²« ë²ˆì§¸ ì˜ˆì¸¡ê°’: {result_data.get('predictions', [])[:3]}\")\n",
    "                \n",
    "                return result_data\n",
    "                \n",
    "            except Exception as e:\n",
    "                if i == 299:\n",
    "                    print(f\"âŒ ì‹œê°„ ì´ˆê³¼: {e}\")\n",
    "                    return None\n",
    "                time.sleep(1)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# ê¸°ì¡´ ë°ì´í„°ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "result = quick_test_existing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "116777d3-a12d-4309-b406-3f55fab15e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 5, 'model_type': 'LinearRegression', 'predictions': [235.89103074363646, 189.13505980296617, 67.24663906673294, 278.6047574023252, 146.57656140507495]}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "40e14ecf-b6f2-4157-8ffc-cb91b8060fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” test-async-endpoint3 ë¬¸ì œ ì§„ë‹¨ ì‹œì‘\n",
      "âœ… Endpoint ìƒíƒœ: InService\n",
      "âœ… Endpoint Config: test-async-endpoint3\n",
      "âœ… Variant: AllTraffic\n",
      "âœ… Instance Type: ml.m5.large\n",
      "âœ… Model Name: sagemaker-2025-09-03-07-43-51-231\n",
      "âœ… Async Output Path: s3://greenenergy-ai-app-d-an2-s3-gem/async-inference/output/\n",
      "âœ… Async Failure Path: N/A\n",
      "âœ… ì…ë ¥ ë°ì´í„° í™•ì¸: 5ê°œ ìƒ˜í”Œ\n",
      "âœ… ì…ë ¥ ë°ì´í„° ì˜ˆì‹œ: [[1.0, 2.0], [3.0, -1.0]]\n",
      "âœ… ì¶”ë¡  ID: 424593f2-6842-4453-a110-7f35bab74b65\n",
      "âœ… ì¶œë ¥ ìœ„ì¹˜: s3://greenenergy-ai-app-d-an2-s3-gem/async-inference/output/e66e8859-e10c-4ae4-a065-9478e92e1a43.out\n",
      "âœ… ì˜¤ë¥˜ ìœ„ì¹˜: s3://greenenergy-ai-app-d-an2-s3-gem/async-inference/error/e66e8859-e10c-4ae4-a065-9478e92e1a43-error.out\n",
      "â³ ëŒ€ê¸° ì¤‘... (0ì´ˆ)\n",
      "âœ… ì„±ê³µ! (5.0ì´ˆ)\n",
      "ğŸ“ˆ ê²°ê³¼: {'batch_size': 5, 'model_type': 'LinearRegression', 'predictions': [235.89103074363646, 189.13505980296617, 67.24663906673294, 278.6047574023252, 146.57656140507495]}\n",
      "{'batch_size': 5, 'model_type': 'LinearRegression', 'predictions': [235.89103074363646, 189.13505980296617, 67.24663906673294, 278.6047574023252, 146.57656140507495]}\n"
     ]
    }
   ],
   "source": [
    "def diagnose_async_issue():\n",
    "    \"\"\"\n",
    "    Async endpoint ë¬¸ì œ ì§„ë‹¨\n",
    "    \"\"\"\n",
    "    endpoint_name = \"test-async-endpoint3\"\n",
    "    input_data = \"s3://greenenergy-ai-app-d-an2-s3-gem/async-inference-input/test-20250729100023.json\"\n",
    "    \n",
    "    print(f\"ğŸ” {endpoint_name} ë¬¸ì œ ì§„ë‹¨ ì‹œì‘\")\n",
    "    \n",
    "    runtime = boto3.client('sagemaker-runtime')\n",
    "    s3 = boto3.client('s3')\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "    \n",
    "    # 1. Endpoint ìƒíƒœ í™•ì¸\n",
    "    try:\n",
    "        endpoint_info = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        print(f\"âœ… Endpoint ìƒíƒœ: {endpoint_info['EndpointStatus']}\")\n",
    "        print(f\"âœ… Endpoint Config: {endpoint_info['EndpointConfigName']}\")\n",
    "        \n",
    "        # Endpoint Config ìƒì„¸ ì •ë³´\n",
    "        config_info = sagemaker_client.describe_endpoint_config(\n",
    "            EndpointConfigName=endpoint_info['EndpointConfigName']\n",
    "        )\n",
    "        \n",
    "        for variant in config_info['ProductionVariants']:\n",
    "            print(f\"âœ… Variant: {variant['VariantName']}\")\n",
    "            print(f\"âœ… Instance Type: {variant['InstanceType']}\")\n",
    "            print(f\"âœ… Model Name: {variant['ModelName']}\")\n",
    "            \n",
    "            # Async Config í™•ì¸\n",
    "            if 'AsyncInferenceConfig' in config_info:\n",
    "                async_config = config_info['AsyncInferenceConfig']\n",
    "                print(f\"âœ… Async Output Path: {async_config.get('OutputConfig', {}).get('S3OutputPath', 'N/A')}\")\n",
    "                print(f\"âœ… Async Failure Path: {async_config.get('OutputConfig', {}).get('S3FailureOutputPath', 'N/A')}\")\n",
    "            else:\n",
    "                print(\"âŒ Async Configê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ!\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Endpoint ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 2. ì…ë ¥ ë°ì´í„° í™•ì¸\n",
    "    try:\n",
    "        bucket = input_data.split('/')[2]\n",
    "        key = '/'.join(input_data.split('/')[3:])\n",
    "        \n",
    "        input_obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "        input_content = json.loads(input_obj['Body'].read())\n",
    "        print(f\"âœ… ì…ë ¥ ë°ì´í„° í™•ì¸: {len(input_content.get('instances', []))}ê°œ ìƒ˜í”Œ\")\n",
    "        print(f\"âœ… ì…ë ¥ ë°ì´í„° ì˜ˆì‹œ: {input_content.get('instances', [])[:2]}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì…ë ¥ ë°ì´í„° í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 3. ë¹„ë™ê¸° ì¶”ë¡  ìš”ì²­ ë° ì˜¤ë¥˜ í™•ì¸\n",
    "    try:\n",
    "        response = runtime.invoke_endpoint_async(\n",
    "            EndpointName=endpoint_name,\n",
    "            InputLocation=input_data,\n",
    "            ContentType='application/json'\n",
    "        )\n",
    "        \n",
    "        output_location = response['OutputLocation']\n",
    "        failure_location = response['FailureLocation']\n",
    "        inference_id = response['InferenceId']\n",
    "        \n",
    "        print(f\"âœ… ì¶”ë¡  ID: {inference_id}\")\n",
    "        print(f\"âœ… ì¶œë ¥ ìœ„ì¹˜: {output_location}\")\n",
    "        print(f\"âœ… ì˜¤ë¥˜ ìœ„ì¹˜: {failure_location}\")\n",
    "        \n",
    "        # 4. ê²°ê³¼ ëŒ€ê¸° ë° ì˜¤ë¥˜ í™•ì¸\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i in range(12):  # 10ë¶„ ëŒ€ê¸°\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            # ì„±ê³µ ê²°ê³¼ í™•ì¸\n",
    "            try:\n",
    "                bucket = output_location.split('/')[2]\n",
    "                key = '/'.join(output_location.split('/')[3:])\n",
    "                \n",
    "                result_obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "                result_data = json.loads(result_obj['Body'].read())\n",
    "                \n",
    "                print(f\"âœ… ì„±ê³µ! ({elapsed:.1f}ì´ˆ)\")\n",
    "                print(f\"ğŸ“ˆ ê²°ê³¼: {result_data}\")\n",
    "                return result_data\n",
    "                \n",
    "            except s3.exceptions.NoSuchKey:\n",
    "                pass  # ì•„ì§ ê²°ê³¼ ì—†ìŒ\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ê²°ê³¼ ì½ê¸° ì˜¤ë¥˜: {e}\")\n",
    "            \n",
    "            # ì‹¤íŒ¨ ê²°ê³¼ í™•ì¸\n",
    "            try:\n",
    "                bucket = failure_location.split('/')[2]\n",
    "                key = '/'.join(failure_location.split('/')[3:])\n",
    "                \n",
    "                error_obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "                error_data = error_obj['Body'].read().decode('utf-8')\n",
    "                \n",
    "                print(f\"âŒ ì¶”ë¡  ì‹¤íŒ¨! ({elapsed:.1f}ì´ˆ)\")\n",
    "                print(f\"ğŸš¨ ì˜¤ë¥˜ ë‚´ìš©: {error_data}\")\n",
    "                return None\n",
    "                \n",
    "            except s3.exceptions.NoSuchKey:\n",
    "                pass  # ì•„ì§ ì˜¤ë¥˜ ì—†ìŒ\n",
    "            except Exception as e:\n",
    "                if i % 12 == 0:  # 1ë¶„ë§ˆë‹¤\n",
    "                    print(f\"â³ ëŒ€ê¸° ì¤‘... ({elapsed:.0f}ì´ˆ) - ì˜¤ë¥˜ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "            \n",
    "            if i % 12 == 0:  # 1ë¶„ë§ˆë‹¤ ì§„í–‰ìƒí™© ì¶œë ¥\n",
    "                print(f\"â³ ëŒ€ê¸° ì¤‘... ({elapsed:.0f}ì´ˆ)\")\n",
    "            \n",
    "            time.sleep(5)\n",
    "        \n",
    "        print(\"âŒ 10ë¶„ ëŒ€ê¸° í›„ ì‹œê°„ ì´ˆê³¼\")\n",
    "        print(\"ğŸ’¡ ìˆ˜ë™ìœ¼ë¡œ S3 í™•ì¸:\")\n",
    "        print(f\"   ì¶œë ¥: {output_location}\")\n",
    "        print(f\"   ì˜¤ë¥˜: {failure_location}\")\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë¹„ë™ê¸° ì¶”ë¡  ìš”ì²­ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "### 10.12 S3 ê²½ë¡œ ìˆ˜ë™ í™•ì¸\n",
    "def check_s3_paths():\n",
    "    \"\"\"\n",
    "    S3 ê²½ë¡œë“¤ì„ ìˆ˜ë™ìœ¼ë¡œ í™•ì¸\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    bucket = 'greenenergy-ai-app-d-an2-s3-gem'\n",
    "    \n",
    "    paths_to_check = [\n",
    "        'async-inference/output/',\n",
    "        'async-inference/error/',\n",
    "        'async-inference-input/'\n",
    "    ]\n",
    "    \n",
    "    for path in paths_to_check:\n",
    "        try:\n",
    "            response = s3.list_objects_v2(Bucket=bucket, Prefix=path, MaxKeys=10)\n",
    "            \n",
    "            if 'Contents' in response:\n",
    "                print(f\"âœ… {path}: {len(response['Contents'])}ê°œ íŒŒì¼\")\n",
    "                for obj in response['Contents'][:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ\n",
    "                    print(f\"   - {obj['Key']} ({obj['Size']} bytes, {obj['LastModified']})\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ {path}: íŒŒì¼ ì—†ìŒ\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {path} í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "\n",
    "result = diagnose_async_issue()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13e46bd2-2889-4bb0-a472-073b627c28f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” greenenergy-ai-app-d-an2-s3-gem/async-inference/error/ ì—ëŸ¬ ë¡œê·¸ í™•ì¸\n",
      "âœ… 4ê°œì˜ ì—ëŸ¬ íŒŒì¼ ë°œê²¬\n",
      "\n",
      "ğŸ“„ ì—ëŸ¬ íŒŒì¼ 1: async-inference/error/f90646e3-2489-470b-bb9a-9ca3c3a276ec-error.out\n",
      "   ì‹œê°„: 2025-09-03 06:21:11+00:00\n",
      "   í¬ê¸°: 145 bytes\n",
      "ğŸš¨ ì—ëŸ¬ ë‚´ìš©:\n",
      "==================================================\n",
      "Timed out uploading object (bucket: greenenergy-ai-app-d-an2-s3-gem, key: async-inference/error/f90646e3-2489-470b-bb9a-9ca3c3a276ec-error.out).\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ“„ ì—ëŸ¬ íŒŒì¼ 2: async-inference/error/72d8426f-1a76-48f5-a1d2-58829fc310e8-error.out\n",
      "   ì‹œê°„: 2025-09-03 06:20:36+00:00\n",
      "   í¬ê¸°: 145 bytes\n",
      "ğŸš¨ ì—ëŸ¬ ë‚´ìš©:\n",
      "==================================================\n",
      "Timed out uploading object (bucket: greenenergy-ai-app-d-an2-s3-gem, key: async-inference/error/72d8426f-1a76-48f5-a1d2-58829fc310e8-error.out).\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ“„ ì—ëŸ¬ íŒŒì¼ 3: async-inference/error/30b20017-80f4-4a53-b8d5-5f842eaa79ba-error.out\n",
      "   ì‹œê°„: 2025-09-03 06:17:48+00:00\n",
      "   í¬ê¸°: 145 bytes\n",
      "ğŸš¨ ì—ëŸ¬ ë‚´ìš©:\n",
      "==================================================\n",
      "Timed out uploading object (bucket: greenenergy-ai-app-d-an2-s3-gem, key: async-inference/error/30b20017-80f4-4a53-b8d5-5f842eaa79ba-error.out).\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Key': 'async-inference/error/f90646e3-2489-470b-bb9a-9ca3c3a276ec-error.out',\n",
       "  'LastModified': datetime.datetime(2025, 9, 3, 6, 21, 11, tzinfo=tzlocal()),\n",
       "  'ETag': '\"4ad8ef6434f368b484780a7d52a50317\"',\n",
       "  'ChecksumAlgorithm': ['CRC64NVME'],\n",
       "  'ChecksumType': 'FULL_OBJECT',\n",
       "  'Size': 145,\n",
       "  'StorageClass': 'STANDARD'},\n",
       " {'Key': 'async-inference/error/72d8426f-1a76-48f5-a1d2-58829fc310e8-error.out',\n",
       "  'LastModified': datetime.datetime(2025, 9, 3, 6, 20, 36, tzinfo=tzlocal()),\n",
       "  'ETag': '\"98d0e728477a275be3e4571c612d79c7\"',\n",
       "  'ChecksumAlgorithm': ['CRC64NVME'],\n",
       "  'ChecksumType': 'FULL_OBJECT',\n",
       "  'Size': 145,\n",
       "  'StorageClass': 'STANDARD'},\n",
       " {'Key': 'async-inference/error/30b20017-80f4-4a53-b8d5-5f842eaa79ba-error.out',\n",
       "  'LastModified': datetime.datetime(2025, 9, 3, 6, 17, 48, tzinfo=tzlocal()),\n",
       "  'ETag': '\"9154e81d5a496a03daa8b7eba9f7df89\"',\n",
       "  'ChecksumAlgorithm': ['CRC64NVME'],\n",
       "  'ChecksumType': 'FULL_OBJECT',\n",
       "  'Size': 145,\n",
       "  'StorageClass': 'STANDARD'},\n",
       " {'Key': 'async-inference/error/b5ae3513-1048-4455-a46b-e78480ae79dd-error.out',\n",
       "  'LastModified': datetime.datetime(2025, 9, 3, 6, 17, 41, tzinfo=tzlocal()),\n",
       "  'ETag': '\"a8cd2cdae6cc2b3b66d54f7d37088f71\"',\n",
       "  'ChecksumAlgorithm': ['CRC64NVME'],\n",
       "  'ChecksumType': 'FULL_OBJECT',\n",
       "  'Size': 145,\n",
       "  'StorageClass': 'STANDARD'}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_recent_errors():\n",
    "    \"\"\"\n",
    "    S3ì—ì„œ ìµœê·¼ ì—ëŸ¬ ë¡œê·¸ë“¤ì„ ì§ì ‘ í™•ì¸\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    bucket = 'greenenergy-ai-app-d-an2-s3-gem'\n",
    "    error_prefix = 'async-inference/error/'\n",
    "    \n",
    "    print(f\"ğŸ” {bucket}/{error_prefix} ì—ëŸ¬ ë¡œê·¸ í™•ì¸\")\n",
    "    \n",
    "    try:\n",
    "        # ìµœê·¼ ì—ëŸ¬ íŒŒì¼ë“¤ ê°€ì ¸ì˜¤ê¸°\n",
    "        response = s3.list_objects_v2(\n",
    "            Bucket=bucket, \n",
    "            Prefix=error_prefix, \n",
    "            MaxKeys=20\n",
    "        )\n",
    "        \n",
    "        if 'Contents' not in response:\n",
    "            print(\"âš ï¸ ì—ëŸ¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        # ìµœì‹  ìˆœìœ¼ë¡œ ì •ë ¬\n",
    "        error_files = sorted(\n",
    "            response['Contents'], \n",
    "            key=lambda x: x['LastModified'], \n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… {len(error_files)}ê°œì˜ ì—ëŸ¬ íŒŒì¼ ë°œê²¬\")\n",
    "        \n",
    "        # ìµœê·¼ 3ê°œ ì—ëŸ¬ íŒŒì¼ ë‚´ìš© í™•ì¸\n",
    "        for i, error_file in enumerate(error_files[:3]):\n",
    "            print(f\"\\nğŸ“„ ì—ëŸ¬ íŒŒì¼ {i+1}: {error_file['Key']}\")\n",
    "            print(f\"   ì‹œê°„: {error_file['LastModified']}\")\n",
    "            print(f\"   í¬ê¸°: {error_file['Size']} bytes\")\n",
    "            \n",
    "            try:\n",
    "                # ì—ëŸ¬ ë‚´ìš© ì½ê¸°\n",
    "                error_obj = s3.get_object(Bucket=bucket, Key=error_file['Key'])\n",
    "                error_content = error_obj['Body'].read().decode('utf-8')\n",
    "                \n",
    "                print(f\"ğŸš¨ ì—ëŸ¬ ë‚´ìš©:\")\n",
    "                print(f\"{'='*50}\")\n",
    "                print(error_content)\n",
    "                print(f\"{'='*50}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ì—ëŸ¬ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        return error_files\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì—ëŸ¬ ë¡œê·¸ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "check_recent_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a45275-fc1e-4352-a26a-bce4597d9642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNS ì•Œë¦¼ì„ í¬í•¨í•œ endpoint ì—…ë°ì´íŠ¸\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "endpoint_name = \"test-async-endpoint3\"\n",
    "sns_topic_arn = \"arn:aws:sns:ap-northeast-2:154126116352:sagemaker-async-notifications\"\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "# ê¸°ì¡´ endpoint ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "endpoint_info = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "config_info = sm_client.describe_endpoint_config(\n",
    "    EndpointConfigName=endpoint_info['EndpointConfigName']\n",
    ")\n",
    "\n",
    "model_name = config_info['ProductionVariants'][0]['ModelName']\n",
    "instance_type = config_info['ProductionVariants'][0]['InstanceType']\n",
    "\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Instance: {instance_type}\")\n",
    "\n",
    "# SNS ì•Œë¦¼ì´ í¬í•¨ëœ ìƒˆë¡œìš´ endpoint configuration ìƒì„±\n",
    "new_config_name = f\"{endpoint_name}-sns-{int(time.time())}\"\n",
    "\n",
    "sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=new_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': 'primary',\n",
    "            'ModelName': model_name,\n",
    "            'InitialInstanceCount': 1,\n",
    "            'InstanceType': instance_type,\n",
    "            'InitialVariantWeight': 1\n",
    "        }\n",
    "    ],\n",
    "    AsyncInferenceConfig={\n",
    "        'OutputConfig': {\n",
    "            'S3OutputPath': 's3://greenenergy-ai-app-d-an2-s3-gem/async-inference/output/',\n",
    "            'NotificationConfig': {\n",
    "                'SuccessTopic': sns_topic_arn,\n",
    "                'ErrorTopic': sns_topic_arn\n",
    "            },\n",
    "            'S3FailurePath': 's3://greenenergy-ai-app-d-an2-s3-gem/async-inference/error/'\n",
    "        },\n",
    "        'ClientConfig': {\n",
    "            'MaxConcurrentInvocationsPerInstance': 4\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"âœ… ìƒˆë¡œìš´ config ìƒì„±: {new_config_name}\")\n",
    "\n",
    "# Endpoint ì—…ë°ì´íŠ¸\n",
    "sm_client.update_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=new_config_name\n",
    ")\n",
    "\n",
    "print(f\"ğŸ”„ Endpoint ì—…ë°ì´íŠ¸ ì‹œì‘ (SNS ì•Œë¦¼ í¬í•¨)\")\n",
    "print(\"â³ ì•½ 5-10ë¶„ ì†Œìš”ë©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9064a5-fdf3-4df0-95ba-90fdd8a85b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNS ì•Œë¦¼ ì„¤ì • í™•ì¸\n",
    "def check_sns_config():\n",
    "    try:\n",
    "        endpoint_info = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        config_info = sm_client.describe_endpoint_config(\n",
    "            EndpointConfigName=endpoint_info['EndpointConfigName']\n",
    "        )\n",
    "        \n",
    "        print(f\"ğŸ“‹ Endpoint ì •ë³´:\")\n",
    "        print(f\"  - Name: {endpoint_info['EndpointName']}\")\n",
    "        print(f\"  - Status: {endpoint_info['EndpointStatus']}\")\n",
    "        print(f\"  - Config: {endpoint_info['EndpointConfigName']}\")\n",
    "        \n",
    "        # Async Config í™•ì¸\n",
    "        if 'AsyncInferenceConfig' in config_info:\n",
    "            async_config = config_info['AsyncInferenceConfig']\n",
    "            output_config = async_config.get('OutputConfig', {})\n",
    "            notification_config = output_config.get('NotificationConfig', {})\n",
    "            \n",
    "            print(f\"\\nğŸ”” SNS ì•Œë¦¼ ì„¤ì •:\")\n",
    "            print(f\"  - Success Topic: {notification_config.get('SuccessTopic', 'N/A')}\")\n",
    "            print(f\"  - Error Topic: {notification_config.get('ErrorTopic', 'N/A')}\")\n",
    "            print(f\"  - Output Path: {output_config.get('S3OutputPath', 'N/A')}\")\n",
    "            print(f"  - Failure Path: {output_config.get('S3FailurePath', 'N/A')}")\n",
    "            \n",
    "            if notification_config.get('SuccessTopic'):\n",
    "                print(\"\\nâœ… SNS ì•Œë¦¼ì´ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "            else:\n",
    "                print(\"\\nâš ï¸ SNS ì•Œë¦¼ì´ ì•„ì§ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì„¤ì • í™•ì¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "# ì„¤ì • í™•ì¸ ì‹¤í–‰\n",
    "check_sns_config()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
