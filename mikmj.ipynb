{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8b4b2d3b-d706-425a-8aa4-e3bd40d4e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, sagemaker, joblib, os, tarfile, subprocess, time\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "import json\n",
    "\n",
    "# SageMaker 세션 및 역할 설정\n",
    "sagemaker_session = sagemaker.Session()\n",
    "#model_data = \"s3://greenenergy-ai-app-d-an2-s3-gem/sagemaker-models/async-20250729100023/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e40201fd-29d9-478f-aba2-0656aa6fffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "377e4fc3-9671-4c1a-a104-5a54bf7ca8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "69f32346-fe0d-4165-a37c-d74a9524fc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id = sagemaker_session.account_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "086c5995-d5f6-4600-b0d5-616aa06fb835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role :arn:aws:iam::154126116352:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\n",
      "region :ap-northeast-2\n",
      "id :154126116352\n"
     ]
    }
   ],
   "source": [
    "print(\"role :\" + role)\n",
    "print(\"region :\" + region)\n",
    "print(\"id :\" + account_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c98f4795-204f-4be9-b660-f4f324828bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델 생성 완료 - R²: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "X, y = make_regression(n_samples=100, n_features=2, random_state=42)\n",
    "model = LinearRegression().fit(X, y)\n",
    "os.makedirs('model', exist_ok=True)\n",
    "joblib.dump(model, 'model/model.joblib')\n",
    "print(f\"✅ 모델 생성 완료 - R²: {model.score(X, y):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aae2b53d-e311-4be5-a26a-d84e5fbcf151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 컨테이너 파일 생성 완료 (Async 최적화)\n"
     ]
    }
   ],
   "source": [
    "# 컨테이너 파일 생성 (Async용)\n",
    "os.makedirs('container', exist_ok=True)\n",
    "\n",
    "# predictor.py (Async 처리 최적화)\n",
    "predictor = '''import joblib, numpy as np, json, os\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "model = joblib.load('/opt/ml/model/model.joblib')\n",
    "\n",
    "@app.route('/ping')\n",
    "def ping():\n",
    "    return jsonify({'status': 'healthy'})\n",
    "\n",
    "@app.route('/invocations', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        # Content-Type 확인\n",
    "        content_type = request.content_type\n",
    "        \n",
    "        if content_type == 'application/json':\n",
    "            data = request.get_json()\n",
    "        else:\n",
    "            # 텍스트 데이터 처리 (CSV 등)\n",
    "            data_str = request.data.decode('utf-8')\n",
    "            data = json.loads(data_str)\n",
    "        \n",
    "        instances = data.get('instances', data)\n",
    "        \n",
    "        # 대용량 데이터 처리를 위한 배치 처리\n",
    "        if isinstance(instances, list) and len(instances) > 1000:\n",
    "            print(f\"Processing large batch: {len(instances)} instances\")\n",
    "        \n",
    "        predictions = model.predict(np.array(instances))\n",
    "        \n",
    "        return jsonify({\n",
    "            'predictions': predictions.tolist(),\n",
    "            'batch_size': len(instances),\n",
    "            'model_type': 'LinearRegression'\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8080)\n",
    "'''\n",
    "\n",
    "# Dockerfile\n",
    "dockerfile = '''FROM python:3.8-slim\n",
    "RUN pip install flask scikit-learn joblib numpy\n",
    "COPY predictor.py /opt/program/predictor.py\n",
    "WORKDIR /opt/program\n",
    "EXPOSE 8080\n",
    "ENTRYPOINT [\"python\", \"predictor.py\"]\n",
    "'''\n",
    "\n",
    "with open('container/predictor.py', 'w') as f: f.write(predictor)\n",
    "with open('container/Dockerfile', 'w') as f: f.write(dockerfile)\n",
    "\n",
    "print(\"✅ 컨테이너 파일 생성 완료 (Async 최적화)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c3fb028c-2ab4-40e7-9c4f-829adb535b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️  ECR 리포지토리 이미 존재: ns-gem/sagemaker\n",
      "📦 ECR URI: 154126116352.dkr.ecr.ap-northeast-2.amazonaws.com/ns-gem/sagemaker\n"
     ]
    }
   ],
   "source": [
    "# ECR 설정\n",
    "ecr = boto3.client('ecr')\n",
    "repo_name = 'ns-gem/sagemaker'\n",
    "try:\n",
    "    ecr.create_repository(repositoryName=repo_name)\n",
    "    print(f\"✅ ECR 리포지토리 생성: {repo_name}\")\n",
    "except ecr.exceptions.RepositoryAlreadyExistsException:\n",
    "    print(f\"ℹ️  ECR 리포지토리 이미 존재: {repo_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"ℹ️  ECR 설정: {str(e)}\")\n",
    "\n",
    "repo_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{repo_name}\"\n",
    "print(f\"📦 ECR URI: {repo_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "de84a39c-4b59-4d33-9f9f-ab1022814415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔨 Docker 빌드 & 푸시 시작...\n",
      "✅ Docker 빌드 & 푸시 완료\n",
      "  8d853c8add5d: Layer already exists\n",
      "  c3772b569c3a: Layer already exists\n",
      "  async: digest: sha256:086f2981fd0f2f850f1a73fbf448e950299cdfe9f859373b5004044b06d78edc size: 1785\n",
      "  ✅ 완료!\n"
     ]
    }
   ],
   "source": [
    "# Docker 빌드 & 푸시\n",
    "build_script = f'''#!/bin/bash\n",
    "set -e\n",
    "echo \"🔐 ECR 로그인...\"\n",
    "aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin {account_id}.dkr.ecr.{region}.amazonaws.com\n",
    "\n",
    "echo \"🔨 Docker 빌드...\"\n",
    "cd container\n",
    "docker build --platform linux/amd64 -t ns-gem-async .\n",
    "\n",
    "echo \"🏷️  태그 설정...\"\n",
    "docker tag ns-gem-async:latest {repo_uri}:async\n",
    "\n",
    "echo \"📤 ECR 푸시...\"\n",
    "docker push {repo_uri}:async\n",
    "\n",
    "echo \"✅ 완료!\"\n",
    "'''\n",
    "\n",
    "with open('build_async.sh', 'w') as f: f.write(build_script)\n",
    "os.chmod('build_async.sh', 0o755)\n",
    "\n",
    "print(\"🔨 Docker 빌드 & 푸시 시작...\")\n",
    "result = subprocess.run(['bash', 'build_async.sh'], capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"✅ Docker 빌드 & 푸시 완료\")\n",
    "    # 마지막 몇 줄만 출력\n",
    "    output_lines = result.stdout.split('\\n')\n",
    "    for line in output_lines[-5:]:\n",
    "        if line.strip():\n",
    "            print(f\"  {line}\")\n",
    "else:\n",
    "    print(f\"❌ 빌드 실패\")\n",
    "    print(f\"STDOUT: {result.stdout}\")\n",
    "    print(f\"STDERR: {result.stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "92012cda-9b28-4c81-a42d-d892ae6a9d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 모델 S3 업로드 중...\n",
      "✅ 모델 업로드 완료: s3://greenenergy-ai-app-d-an2-s3-gem/sagemaker-models/async-20250903074245-test/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# 모델 S3 업로드\n",
    "print(\"📦 모델 S3 업로드 중...\")\n",
    "bucket_name = 'greenenergy-ai-app-d-an2-s3-gem'\n",
    "with tarfile.open('model.tar.gz', 'w:gz') as tar:\n",
    "    tar.add('model/model.joblib', arcname='model.joblib')\n",
    "\n",
    "# 지정된 S3 버킷 사용\n",
    "s3 = boto3.client('s3')\n",
    "timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "s3_key = f'sagemaker-models/async-{timestamp}-test/model.tar.gz'\n",
    "\n",
    "s3.upload_file('model.tar.gz', bucket_name, s3_key)\n",
    "model_uri = f's3://{bucket_name}/{s3_key}'\n",
    "\n",
    "print(f\"✅ 모델 업로드 완료: {model_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2f00a441-deb7-44ee-bc14-4ae8d514d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model_data=model_uri\n",
    "model = Model(\n",
    "    image_uri=f'{repo_uri}:async',\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e5041890-1aa4-4ad1-871c-faf73ce45c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async Inference 설정 (SNS 알림 포함)\n",
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "\n",
    "# SNS 토픽 ARN\n",
    "sns_topic_arn = \"arn:aws:sns:ap-northeast-2:154126116352:sagemaker-async-notifications\"\n",
    "\n",
    "async_config = AsyncInferenceConfig(\n",
    "    output_path=\"s3://greenenergy-ai-app-d-an2-s3-gem/async-inference/output/\",\n",
    "    max_concurrent_invocations_per_instance=4,\n",
    "    failure_path=\"s3://greenenergy-ai-app-d-an2-s3-gem/async-inference/error/\",\n",
    "    notification_config={\n",
    "        \"SuccessTopic\": sns_topic_arn,\n",
    "        \"ErrorTopic\": sns_topic_arn\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"✅ Async Inference Config with SNS notifications created\")\n",
    "print(f\"SNS Topic: {sns_topic_arn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "470a1f80-ebaa-4cb2-a407-c088e4fc2b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "# Async Endpoint 배포\n",
    "try:\n",
    "    predictor = model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        async_inference_config=async_config,\n",
    "        endpoint_name=\"test-async-endpoint3\"  # 선택사항\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 배포 중 오류: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "039d3fa8-bbbc-49b9-928d-468bce6d39c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_s3_uri = \"s3://greenenergy-ai-app-d-an2-s3-gem/async-inference-input/test-20250729100023.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "912b40e2-c51c-4c01-a3fa-afadeb4b33d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 기존 데이터로 빠른 테스트 시작\n",
      "입력 데이터: s3://greenenergy-ai-app-d-an2-s3-gem/async-inference-input/test-20250729100023.json\n",
      "{'ResponseMetadata': {'RequestId': 'bfa32a4f-04cb-4677-aa97-89520f6cafc5', 'HTTPStatusCode': 202, 'HTTPHeaders': {'x-amzn-requestid': 'bfa32a4f-04cb-4677-aa97-89520f6cafc5', 'x-amzn-sagemaker-outputlocation': 's3://greenenergy-ai-app-d-an2-s3-gem/async-inference/output/49779a19-b2b9-4c5e-8a48-1c38ba631ec2.out', 'x-amzn-sagemaker-failurelocation': 's3://greenenergy-ai-app-d-an2-s3-gem/async-inference/error/49779a19-b2b9-4c5e-8a48-1c38ba631ec2-error.out', 'date': 'Wed, 03 Sep 2025 07:47:26 GMT', 'content-type': 'application/json', 'content-length': '54', 'connection': 'keep-alive'}, 'RetryAttempts': 0}, 'OutputLocation': 's3://greenenergy-ai-app-d-an2-s3-gem/async-inference/output/49779a19-b2b9-4c5e-8a48-1c38ba631ec2.out', 'FailureLocation': 's3://greenenergy-ai-app-d-an2-s3-gem/async-inference/error/49779a19-b2b9-4c5e-8a48-1c38ba631ec2-error.out', 'InferenceId': '285c9f19-ac87-4108-91ab-34298e0e6305'}\n",
      "출력 위치: s3://greenenergy-ai-app-d-an2-s3-gem/async-inference/output/49779a19-b2b9-4c5e-8a48-1c38ba631ec2.out\n",
      "greenenergy-ai-app-d-an2-s3-gem\n",
      "async-inference/output/49779a19-b2b9-4c5e-8a48-1c38ba631ec2.out\n",
      "greenenergy-ai-app-d-an2-s3-gem\n",
      "async-inference/output/49779a19-b2b9-4c5e-8a48-1c38ba631ec2.out\n",
      "{'ResponseMetadata': {'RequestId': 'A4BAP9WDNDKAKSHY', 'HostId': 'jjrF/r/kdrzEW5OrPd6bzuMuPvluhEV2X/aR0cmwMKGJ0QSjNN3yf6cQdw/qNhb197sHbBGpXsY=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': 'jjrF/r/kdrzEW5OrPd6bzuMuPvluhEV2X/aR0cmwMKGJ0QSjNN3yf6cQdw/qNhb197sHbBGpXsY=', 'x-amz-request-id': 'A4BAP9WDNDKAKSHY', 'date': 'Wed, 03 Sep 2025 07:47:28 GMT', 'last-modified': 'Wed, 03 Sep 2025 07:47:28 GMT', 'etag': '\"1b331023795dea304e6b9069eb758951\"', 'x-amz-checksum-crc64nvme': 'qn0Jf7MXEPI=', 'x-amz-checksum-type': 'FULL_OBJECT', 'x-amz-server-side-encryption': 'aws:kms', 'x-amz-server-side-encryption-aws-kms-key-id': 'arn:aws:kms:ap-northeast-2:ACCOUNT_ID:key/KMS_KEY_ID', 'x-amz-server-side-encryption-bucket-key-enabled': 'true', 'accept-ranges': 'bytes', 'content-type': 'application/json', 'content-length': '158', 'server': 'AmazonS3'}, 'RetryAttempts': 0}, 'AcceptRanges': 'bytes', 'LastModified': datetime.datetime(2025, 9, 3, 7, 47, 28, tzinfo=tzutc()), 'ContentLength': 158, 'ETag': '\"1b331023795dea304e6b9069eb758951\"', 'ChecksumCRC64NVME': 'qn0Jf7MXEPI=', 'ChecksumType': 'FULL_OBJECT', 'ContentType': 'application/json', 'ServerSideEncryption': 'aws:kms', 'Metadata': {}, 'SSEKMSKeyId': 'arn:aws:kms:ap-northeast-2:ACCOUNT_ID:key/KMS_KEY_ID', 'BucketKeyEnabled': True, 'Body': <botocore.response.StreamingBody object at 0x7f33152d4310>}\n",
      "{'batch_size': 5, 'model_type': 'LinearRegression', 'predictions': [235.89103074363646, 189.13505980296617, 67.24663906673294, 278.6047574023252, 146.57656140507495]}\n",
      "✅ 테스트 완료 (1.09초)\n",
      "예측 결과 수: 5\n",
      "배치 크기: 5\n",
      "첫 번째 예측값: [235.89103074363646, 189.13505980296617, 67.24663906673294]\n"
     ]
    }
   ],
   "source": [
    "def quick_test_existing_data():\n",
    "    endpoint_name = \"test-async-endpoint3\"\n",
    "    input_data = input_s3_uri\n",
    "    \n",
    "    print(\"🚀 기존 데이터로 빠른 테스트 시작\")\n",
    "    print(f\"입력 데이터: {input_data}\")\n",
    "    \n",
    "    runtime = boto3.client('sagemaker-runtime')\n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        # Async 추론 요청\n",
    "        response = runtime.invoke_endpoint_async(\n",
    "            EndpointName=endpoint_name,\n",
    "            InputLocation=input_data,\n",
    "            ContentType='application/json'\n",
    "        )\n",
    "        \n",
    "        output_location = response['OutputLocation']\n",
    "        print(response)\n",
    "        print(f\"출력 위치: {output_location}\")\n",
    "        \n",
    "        # 결과 대기\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i in range(300):  # 5분 대기\n",
    "            try:\n",
    "                bucket = output_location.split('/')[2]\n",
    "                print(bucket)\n",
    "                key = '/'.join(output_location.split('/')[3:])\n",
    "                print(key)\n",
    "                \n",
    "                result_obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "                print(result_obj)\n",
    "                result_data = json.loads(result_obj['Body'].read())\n",
    "                print(result_data)\n",
    "                \n",
    "                elapsed_time = time.time() - start_time\n",
    "                print(f\"✅ 테스트 완료 ({elapsed_time:.2f}초)\")\n",
    "                print(f\"예측 결과 수: {len(result_data.get('predictions', []))}\")\n",
    "                print(f\"배치 크기: {result_data.get('batch_size', 'N/A')}\")\n",
    "                print(f\"첫 번째 예측값: {result_data.get('predictions', [])[:3]}\")\n",
    "                \n",
    "                return result_data\n",
    "                \n",
    "            except Exception as e:\n",
    "                if i == 299:\n",
    "                    print(f\"❌ 시간 초과: {e}\")\n",
    "                    return None\n",
    "                time.sleep(1)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 테스트 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "# 기존 데이터로 빠른 테스트 실행\n",
    "result = quick_test_existing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "116777d3-a12d-4309-b406-3f55fab15e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 5, 'model_type': 'LinearRegression', 'predictions': [235.89103074363646, 189.13505980296617, 67.24663906673294, 278.6047574023252, 146.57656140507495]}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "40e14ecf-b6f2-4157-8ffc-cb91b8060fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 test-async-endpoint3 문제 진단 시작\n",
      "✅ Endpoint 상태: InService\n",
      "✅ Endpoint Config: test-async-endpoint3\n",
      "✅ Variant: AllTraffic\n",
      "✅ Instance Type: ml.m5.large\n",
      "✅ Model Name: sagemaker-2025-09-03-07-43-51-231\n",
      "✅ Async Output Path: s3://greenenergy-ai-app-d-an2-s3-gem/async-inference/output/\n",
      "✅ Async Failure Path: N/A\n",
      "✅ 입력 데이터 확인: 5개 샘플\n",
      "✅ 입력 데이터 예시: [[1.0, 2.0], [3.0, -1.0]]\n",
      "✅ 추론 ID: 424593f2-6842-4453-a110-7f35bab74b65\n",
      "✅ 출력 위치: s3://greenenergy-ai-app-d-an2-s3-gem/async-inference/output/e66e8859-e10c-4ae4-a065-9478e92e1a43.out\n",
      "✅ 오류 위치: s3://greenenergy-ai-app-d-an2-s3-gem/async-inference/error/e66e8859-e10c-4ae4-a065-9478e92e1a43-error.out\n",
      "⏳ 대기 중... (0초)\n",
      "✅ 성공! (5.0초)\n",
      "📈 결과: {'batch_size': 5, 'model_type': 'LinearRegression', 'predictions': [235.89103074363646, 189.13505980296617, 67.24663906673294, 278.6047574023252, 146.57656140507495]}\n",
      "{'batch_size': 5, 'model_type': 'LinearRegression', 'predictions': [235.89103074363646, 189.13505980296617, 67.24663906673294, 278.6047574023252, 146.57656140507495]}\n"
     ]
    }
   ],
   "source": [
    "def diagnose_async_issue():\n",
    "    \"\"\"\n",
    "    Async endpoint 문제 진단\n",
    "    \"\"\"\n",
    "    endpoint_name = \"test-async-endpoint3\"\n",
    "    input_data = \"s3://greenenergy-ai-app-d-an2-s3-gem/async-inference-input/test-20250729100023.json\"\n",
    "    \n",
    "    print(f\"🔍 {endpoint_name} 문제 진단 시작\")\n",
    "    \n",
    "    runtime = boto3.client('sagemaker-runtime')\n",
    "    s3 = boto3.client('s3')\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "    \n",
    "    # 1. Endpoint 상태 확인\n",
    "    try:\n",
    "        endpoint_info = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        print(f\"✅ Endpoint 상태: {endpoint_info['EndpointStatus']}\")\n",
    "        print(f\"✅ Endpoint Config: {endpoint_info['EndpointConfigName']}\")\n",
    "        \n",
    "        # Endpoint Config 상세 정보\n",
    "        config_info = sagemaker_client.describe_endpoint_config(\n",
    "            EndpointConfigName=endpoint_info['EndpointConfigName']\n",
    "        )\n",
    "        \n",
    "        for variant in config_info['ProductionVariants']:\n",
    "            print(f\"✅ Variant: {variant['VariantName']}\")\n",
    "            print(f\"✅ Instance Type: {variant['InstanceType']}\")\n",
    "            print(f\"✅ Model Name: {variant['ModelName']}\")\n",
    "            \n",
    "            # Async Config 확인\n",
    "            if 'AsyncInferenceConfig' in config_info:\n",
    "                async_config = config_info['AsyncInferenceConfig']\n",
    "                print(f\"✅ Async Output Path: {async_config.get('OutputConfig', {}).get('S3OutputPath', 'N/A')}\")\n",
    "                print(f\"✅ Async Failure Path: {async_config.get('OutputConfig', {}).get('S3FailureOutputPath', 'N/A')}\")\n",
    "            else:\n",
    "                print(\"❌ Async Config가 설정되지 않음!\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Endpoint 정보 확인 실패: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 2. 입력 데이터 확인\n",
    "    try:\n",
    "        bucket = input_data.split('/')[2]\n",
    "        key = '/'.join(input_data.split('/')[3:])\n",
    "        \n",
    "        input_obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "        input_content = json.loads(input_obj['Body'].read())\n",
    "        print(f\"✅ 입력 데이터 확인: {len(input_content.get('instances', []))}개 샘플\")\n",
    "        print(f\"✅ 입력 데이터 예시: {input_content.get('instances', [])[:2]}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 입력 데이터 확인 실패: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 3. 비동기 추론 요청 및 오류 확인\n",
    "    try:\n",
    "        response = runtime.invoke_endpoint_async(\n",
    "            EndpointName=endpoint_name,\n",
    "            InputLocation=input_data,\n",
    "            ContentType='application/json'\n",
    "        )\n",
    "        \n",
    "        output_location = response['OutputLocation']\n",
    "        failure_location = response['FailureLocation']\n",
    "        inference_id = response['InferenceId']\n",
    "        \n",
    "        print(f\"✅ 추론 ID: {inference_id}\")\n",
    "        print(f\"✅ 출력 위치: {output_location}\")\n",
    "        print(f\"✅ 오류 위치: {failure_location}\")\n",
    "        \n",
    "        # 4. 결과 대기 및 오류 확인\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i in range(12):  # 10분 대기\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            # 성공 결과 확인\n",
    "            try:\n",
    "                bucket = output_location.split('/')[2]\n",
    "                key = '/'.join(output_location.split('/')[3:])\n",
    "                \n",
    "                result_obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "                result_data = json.loads(result_obj['Body'].read())\n",
    "                \n",
    "                print(f\"✅ 성공! ({elapsed:.1f}초)\")\n",
    "                print(f\"📈 결과: {result_data}\")\n",
    "                return result_data\n",
    "                \n",
    "            except s3.exceptions.NoSuchKey:\n",
    "                pass  # 아직 결과 없음\n",
    "            except Exception as e:\n",
    "                print(f\"❌ 결과 읽기 오류: {e}\")\n",
    "            \n",
    "            # 실패 결과 확인\n",
    "            try:\n",
    "                bucket = failure_location.split('/')[2]\n",
    "                key = '/'.join(failure_location.split('/')[3:])\n",
    "                \n",
    "                error_obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "                error_data = error_obj['Body'].read().decode('utf-8')\n",
    "                \n",
    "                print(f\"❌ 추론 실패! ({elapsed:.1f}초)\")\n",
    "                print(f\"🚨 오류 내용: {error_data}\")\n",
    "                return None\n",
    "                \n",
    "            except s3.exceptions.NoSuchKey:\n",
    "                pass  # 아직 오류 없음\n",
    "            except Exception as e:\n",
    "                if i % 12 == 0:  # 1분마다\n",
    "                    print(f\"⏳ 대기 중... ({elapsed:.0f}초) - 오류 확인 실패: {e}\")\n",
    "            \n",
    "            if i % 12 == 0:  # 1분마다 진행상황 출력\n",
    "                print(f\"⏳ 대기 중... ({elapsed:.0f}초)\")\n",
    "            \n",
    "            time.sleep(5)\n",
    "        \n",
    "        print(\"❌ 10분 대기 후 시간 초과\")\n",
    "        print(\"💡 수동으로 S3 확인:\")\n",
    "        print(f\"   출력: {output_location}\")\n",
    "        print(f\"   오류: {failure_location}\")\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 비동기 추론 요청 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "### 10.12 S3 경로 수동 확인\n",
    "def check_s3_paths():\n",
    "    \"\"\"\n",
    "    S3 경로들을 수동으로 확인\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    bucket = 'greenenergy-ai-app-d-an2-s3-gem'\n",
    "    \n",
    "    paths_to_check = [\n",
    "        'async-inference/output/',\n",
    "        'async-inference/error/',\n",
    "        'async-inference-input/'\n",
    "    ]\n",
    "    \n",
    "    for path in paths_to_check:\n",
    "        try:\n",
    "            response = s3.list_objects_v2(Bucket=bucket, Prefix=path, MaxKeys=10)\n",
    "            \n",
    "            if 'Contents' in response:\n",
    "                print(f\"✅ {path}: {len(response['Contents'])}개 파일\")\n",
    "                for obj in response['Contents'][:5]:  # 최대 5개만 표시\n",
    "                    print(f\"   - {obj['Key']} ({obj['Size']} bytes, {obj['LastModified']})\")\n",
    "            else:\n",
    "                print(f\"⚠️ {path}: 파일 없음\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ {path} 확인 실패: {e}\")\n",
    "\n",
    "\n",
    "result = diagnose_async_issue()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13e46bd2-2889-4bb0-a472-073b627c28f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 greenenergy-ai-app-d-an2-s3-gem/async-inference/error/ 에러 로그 확인\n",
      "✅ 4개의 에러 파일 발견\n",
      "\n",
      "📄 에러 파일 1: async-inference/error/f90646e3-2489-470b-bb9a-9ca3c3a276ec-error.out\n",
      "   시간: 2025-09-03 06:21:11+00:00\n",
      "   크기: 145 bytes\n",
      "🚨 에러 내용:\n",
      "==================================================\n",
      "Timed out uploading object (bucket: greenenergy-ai-app-d-an2-s3-gem, key: async-inference/error/f90646e3-2489-470b-bb9a-9ca3c3a276ec-error.out).\n",
      "\n",
      "==================================================\n",
      "\n",
      "📄 에러 파일 2: async-inference/error/72d8426f-1a76-48f5-a1d2-58829fc310e8-error.out\n",
      "   시간: 2025-09-03 06:20:36+00:00\n",
      "   크기: 145 bytes\n",
      "🚨 에러 내용:\n",
      "==================================================\n",
      "Timed out uploading object (bucket: greenenergy-ai-app-d-an2-s3-gem, key: async-inference/error/72d8426f-1a76-48f5-a1d2-58829fc310e8-error.out).\n",
      "\n",
      "==================================================\n",
      "\n",
      "📄 에러 파일 3: async-inference/error/30b20017-80f4-4a53-b8d5-5f842eaa79ba-error.out\n",
      "   시간: 2025-09-03 06:17:48+00:00\n",
      "   크기: 145 bytes\n",
      "🚨 에러 내용:\n",
      "==================================================\n",
      "Timed out uploading object (bucket: greenenergy-ai-app-d-an2-s3-gem, key: async-inference/error/30b20017-80f4-4a53-b8d5-5f842eaa79ba-error.out).\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Key': 'async-inference/error/f90646e3-2489-470b-bb9a-9ca3c3a276ec-error.out',\n",
       "  'LastModified': datetime.datetime(2025, 9, 3, 6, 21, 11, tzinfo=tzlocal()),\n",
       "  'ETag': '\"4ad8ef6434f368b484780a7d52a50317\"',\n",
       "  'ChecksumAlgorithm': ['CRC64NVME'],\n",
       "  'ChecksumType': 'FULL_OBJECT',\n",
       "  'Size': 145,\n",
       "  'StorageClass': 'STANDARD'},\n",
       " {'Key': 'async-inference/error/72d8426f-1a76-48f5-a1d2-58829fc310e8-error.out',\n",
       "  'LastModified': datetime.datetime(2025, 9, 3, 6, 20, 36, tzinfo=tzlocal()),\n",
       "  'ETag': '\"98d0e728477a275be3e4571c612d79c7\"',\n",
       "  'ChecksumAlgorithm': ['CRC64NVME'],\n",
       "  'ChecksumType': 'FULL_OBJECT',\n",
       "  'Size': 145,\n",
       "  'StorageClass': 'STANDARD'},\n",
       " {'Key': 'async-inference/error/30b20017-80f4-4a53-b8d5-5f842eaa79ba-error.out',\n",
       "  'LastModified': datetime.datetime(2025, 9, 3, 6, 17, 48, tzinfo=tzlocal()),\n",
       "  'ETag': '\"9154e81d5a496a03daa8b7eba9f7df89\"',\n",
       "  'ChecksumAlgorithm': ['CRC64NVME'],\n",
       "  'ChecksumType': 'FULL_OBJECT',\n",
       "  'Size': 145,\n",
       "  'StorageClass': 'STANDARD'},\n",
       " {'Key': 'async-inference/error/b5ae3513-1048-4455-a46b-e78480ae79dd-error.out',\n",
       "  'LastModified': datetime.datetime(2025, 9, 3, 6, 17, 41, tzinfo=tzlocal()),\n",
       "  'ETag': '\"a8cd2cdae6cc2b3b66d54f7d37088f71\"',\n",
       "  'ChecksumAlgorithm': ['CRC64NVME'],\n",
       "  'ChecksumType': 'FULL_OBJECT',\n",
       "  'Size': 145,\n",
       "  'StorageClass': 'STANDARD'}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_recent_errors():\n",
    "    \"\"\"\n",
    "    S3에서 최근 에러 로그들을 직접 확인\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    bucket = 'greenenergy-ai-app-d-an2-s3-gem'\n",
    "    error_prefix = 'async-inference/error/'\n",
    "    \n",
    "    print(f\"🔍 {bucket}/{error_prefix} 에러 로그 확인\")\n",
    "    \n",
    "    try:\n",
    "        # 최근 에러 파일들 가져오기\n",
    "        response = s3.list_objects_v2(\n",
    "            Bucket=bucket, \n",
    "            Prefix=error_prefix, \n",
    "            MaxKeys=20\n",
    "        )\n",
    "        \n",
    "        if 'Contents' not in response:\n",
    "            print(\"⚠️ 에러 파일이 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        # 최신 순으로 정렬\n",
    "        error_files = sorted(\n",
    "            response['Contents'], \n",
    "            key=lambda x: x['LastModified'], \n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ {len(error_files)}개의 에러 파일 발견\")\n",
    "        \n",
    "        # 최근 3개 에러 파일 내용 확인\n",
    "        for i, error_file in enumerate(error_files[:3]):\n",
    "            print(f\"\\n📄 에러 파일 {i+1}: {error_file['Key']}\")\n",
    "            print(f\"   시간: {error_file['LastModified']}\")\n",
    "            print(f\"   크기: {error_file['Size']} bytes\")\n",
    "            \n",
    "            try:\n",
    "                # 에러 내용 읽기\n",
    "                error_obj = s3.get_object(Bucket=bucket, Key=error_file['Key'])\n",
    "                error_content = error_obj['Body'].read().decode('utf-8')\n",
    "                \n",
    "                print(f\"🚨 에러 내용:\")\n",
    "                print(f\"{'='*50}\")\n",
    "                print(error_content)\n",
    "                print(f\"{'='*50}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ 에러 파일 읽기 실패: {e}\")\n",
    "        \n",
    "        return error_files\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 에러 로그 확인 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "check_recent_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a45275-fc1e-4352-a26a-bce4597d9642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNS 알림을 포함한 endpoint 업데이트\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "endpoint_name = \"test-async-endpoint3\"\n",
    "sns_topic_arn = \"arn:aws:sns:ap-northeast-2:154126116352:sagemaker-async-notifications\"\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "# 기존 endpoint 정보 가져오기\n",
    "endpoint_info = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "config_info = sm_client.describe_endpoint_config(\n",
    "    EndpointConfigName=endpoint_info['EndpointConfigName']\n",
    ")\n",
    "\n",
    "model_name = config_info['ProductionVariants'][0]['ModelName']\n",
    "instance_type = config_info['ProductionVariants'][0]['InstanceType']\n",
    "\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Instance: {instance_type}\")\n",
    "\n",
    "# SNS 알림이 포함된 새로운 endpoint configuration 생성\n",
    "new_config_name = f\"{endpoint_name}-sns-{int(time.time())}\"\n",
    "\n",
    "sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=new_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': 'primary',\n",
    "            'ModelName': model_name,\n",
    "            'InitialInstanceCount': 1,\n",
    "            'InstanceType': instance_type,\n",
    "            'InitialVariantWeight': 1\n",
    "        }\n",
    "    ],\n",
    "    AsyncInferenceConfig={\n",
    "        'OutputConfig': {\n",
    "            'S3OutputPath': 's3://greenenergy-ai-app-d-an2-s3-gem/async-inference/output/',\n",
    "            'NotificationConfig': {\n",
    "                'SuccessTopic': sns_topic_arn,\n",
    "                'ErrorTopic': sns_topic_arn\n",
    "            },\n",
    "            'S3FailurePath': 's3://greenenergy-ai-app-d-an2-s3-gem/async-inference/error/'\n",
    "        },\n",
    "        'ClientConfig': {\n",
    "            'MaxConcurrentInvocationsPerInstance': 4\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"✅ 새로운 config 생성: {new_config_name}\")\n",
    "\n",
    "# Endpoint 업데이트\n",
    "sm_client.update_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=new_config_name\n",
    ")\n",
    "\n",
    "print(f\"🔄 Endpoint 업데이트 시작 (SNS 알림 포함)\")\n",
    "print(\"⏳ 약 5-10분 소요됩니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9064a5-fdf3-4df0-95ba-90fdd8a85b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNS 알림 설정 확인\n",
    "def check_sns_config():\n",
    "    try:\n",
    "        endpoint_info = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        config_info = sm_client.describe_endpoint_config(\n",
    "            EndpointConfigName=endpoint_info['EndpointConfigName']\n",
    "        )\n",
    "        \n",
    "        print(f\"📋 Endpoint 정보:\")\n",
    "        print(f\"  - Name: {endpoint_info['EndpointName']}\")\n",
    "        print(f\"  - Status: {endpoint_info['EndpointStatus']}\")\n",
    "        print(f\"  - Config: {endpoint_info['EndpointConfigName']}\")\n",
    "        \n",
    "        # Async Config 확인\n",
    "        if 'AsyncInferenceConfig' in config_info:\n",
    "            async_config = config_info['AsyncInferenceConfig']\n",
    "            output_config = async_config.get('OutputConfig', {})\n",
    "            notification_config = output_config.get('NotificationConfig', {})\n",
    "            \n",
    "            print(f\"\\n🔔 SNS 알림 설정:\")\n",
    "            print(f\"  - Success Topic: {notification_config.get('SuccessTopic', 'N/A')}\")\n",
    "            print(f\"  - Error Topic: {notification_config.get('ErrorTopic', 'N/A')}\")\n",
    "            print(f\"  - Output Path: {output_config.get('S3OutputPath', 'N/A')}\")\n",
    "            print(f"  - Failure Path: {output_config.get('S3FailurePath', 'N/A')}")\n",
    "            \n",
    "            if notification_config.get('SuccessTopic'):\n",
    "                print(\"\\n✅ SNS 알림이 성공적으로 설정되었습니다!\")\n",
    "            else:\n",
    "                print(\"\\n⚠️ SNS 알림이 아직 설정되지 않았습니다.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 설정 확인 실패: {str(e)}\")\n",
    "\n",
    "# 설정 확인 실행\n",
    "check_sns_config()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
