import boto3
import sagemaker
from sagemaker.model import Model
from sagemaker.async_inference import AsyncInferenceConfig
from datetime import datetime

# ì„¤ì •
sagemaker_session = sagemaker.Session()
role = sagemaker.get_execution_role()
timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
endpoint_name = f"test-async-endpoint-v{timestamp}"

# ê¸°ì¡´ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì‚¬ìš©
model_data = "s3://greenenergy-ai-app-d-an2-s3-gem/sagemaker-models/async-20250729100023/model.tar.gz"

# ëª¨ë¸ ìƒì„±
model = Model(
    image_uri="763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/sklearn-inference:1.2-1-cpu-py3",
    model_data=model_data,
    role=role,
    sagemaker_session=sagemaker_session
)

# Async ì„¤ì •
async_config = AsyncInferenceConfig(
    output_path="s3://greenenergy-ai-app-d-an2-s3-gem/async-inference/output/",
    max_concurrent_invocations_per_instance=4,
    failure_path="s3://greenenergy-ai-app-d-an2-s3-gem/async-inference/error/"
)

print(f"ğŸš€ ë°°í¬ ì‹œì‘: {endpoint_name}")

# ë°°í¬
predictor = model.deploy(
    initial_instance_count=1,
    instance_type="ml.m5.large",
    endpoint_name=endpoint_name,
    async_inference_config=async_config
)

print(f"âœ… ë°°í¬ ì™„ë£Œ: {endpoint_name}")
print(f"ğŸ“ ì—”ë“œí¬ì¸íŠ¸: {predictor.endpoint_name}")
